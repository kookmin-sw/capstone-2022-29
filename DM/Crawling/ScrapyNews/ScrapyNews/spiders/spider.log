2022-05-10 03:36:49 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 03:36:49 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 03:39:21 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 03:39:21 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 03:39:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 03:39:21 [scrapy.extensions.telnet] INFO: Telnet Password: 25174872c3dc9935
2022-05-10 03:39:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 03:39:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 03:39:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 03:39:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 03:39:21 [scrapy.core.engine] INFO: Spider opened
2022-05-10 03:39:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 03:39:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 03:39:22 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 03:39:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 440,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2018,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.840748,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 9, 18, 39, 22, 854510),
 'httpcache/firsthand': 2,
 'httpcache/miss': 2,
 'httpcache/store': 2,
 'httpcompression/response_bytes': 2512,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 75956224,
 'memusage/startup': 75956224,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 9, 18, 39, 22, 13762)}
2022-05-10 03:39:22 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 03:41:32 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 03:41:32 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 03:41:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 03:41:32 [scrapy.extensions.telnet] INFO: Telnet Password: 8eca03a26bc1f3cd
2022-05-10 03:41:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 03:41:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 03:41:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 03:41:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 03:41:32 [scrapy.core.engine] INFO: Spider opened
2022-05-10 03:41:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 03:41:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 03:41:33 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 03:41:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.342574,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 9, 18, 41, 33, 502373),
 'httpcache/firsthand': 2,
 'httpcache/miss': 2,
 'httpcache/store': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 68141056,
 'memusage/startup': 68141056,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 9, 18, 41, 32, 159799)}
2022-05-10 03:41:33 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 03:41:58 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 03:41:58 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 03:41:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 03:41:58 [scrapy.extensions.telnet] INFO: Telnet Password: 761b7c20f39050c8
2022-05-10 03:41:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 03:41:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 03:41:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 03:41:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 03:41:58 [scrapy.core.engine] INFO: Spider opened
2022-05-10 03:41:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 03:41:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 03:41:58 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 03:41:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.118315,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 9, 18, 41, 58, 246797),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 68829184,
 'memusage/startup': 68829184,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 9, 18, 41, 58, 128482)}
2022-05-10 03:41:58 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 22:28:04 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 22:28:04 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 22:28:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 22:28:04 [scrapy.extensions.telnet] INFO: Telnet Password: 8e4def230793e003
2022-05-10 22:28:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 22:28:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 22:28:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 22:28:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 22:28:04 [scrapy.core.engine] INFO: Spider opened
2022-05-10 22:28:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 22:28:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 22:28:04 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 22:28:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.17469,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 13, 28, 4, 629873),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 67780608,
 'memusage/startup': 67780608,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 13, 28, 4, 455183)}
2022-05-10 22:28:04 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 22:42:55 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 22:42:55 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 22:42:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 22:42:55 [scrapy.extensions.telnet] INFO: Telnet Password: a02f90bb040a0852
2022-05-10 22:42:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 22:42:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 22:42:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 22:42:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 22:42:55 [scrapy.core.engine] INFO: Spider opened
2022-05-10 22:42:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 22:42:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 22:42:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://github.com/Hyewon0223?tab=repositories> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 17, in parse
    print(response.xpath('//*[@id="user-repositories-list"]/ul/li[1]/div[1]/div[1]/h3/a')).extract
AttributeError: 'NoneType' object has no attribute 'extract'
2022-05-10 22:42:55 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 22:42:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.225814,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 13, 42, 55, 817452),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 68173824,
 'memusage/startup': 68173824,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 13, 42, 55, 591638)}
2022-05-10 22:42:55 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:32:22 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:32:22 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:32:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:32:22 [scrapy.extensions.telnet] INFO: Telnet Password: f226ddc6d58fe9ff
2022-05-10 23:32:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:32:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:32:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:32:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:32:22 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:32:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:32:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:32:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://github.com/Hyewon0223?tab=repositories> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 17, in parse
    print(response.xpath('//*[@id="user-repositories-list"]/ul/li[1]/div[1]/div[1]/h3/a/text()')).extract
AttributeError: 'NoneType' object has no attribute 'extract'
2022-05-10 23:32:22 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:32:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.222063,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 32, 22, 813922),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 67665920,
 'memusage/startup': 67665920,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 32, 22, 591859)}
2022-05-10 23:32:22 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:34:14 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:34:14 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:34:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:34:14 [scrapy.extensions.telnet] INFO: Telnet Password: 94275d530a488180
2022-05-10 23:34:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:34:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:34:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:34:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:34:14 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:34:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:34:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:34:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://github.com/Hyewon0223?tab=repositories> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 18, in parse
    print(response.xpath('//*[@id="user-repositories-list"]/ul/li[1]/div[1]/div[1]/h3/a/text()')).extract_first()
AttributeError: 'NoneType' object has no attribute 'extract_first'
2022-05-10 23:34:15 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:34:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.226048,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 34, 15, 46412),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 68599808,
 'memusage/startup': 68599808,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 34, 14, 820364)}
2022-05-10 23:34:15 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:34:34 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:34:34 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:34:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:34:34 [scrapy.extensions.telnet] INFO: Telnet Password: 3c55c2e3f9651d6d
2022-05-10 23:34:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:34:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:34:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:34:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:34:34 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:34:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:34:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:34:35 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:34:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.119147,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 34, 35, 95274),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69533696,
 'memusage/startup': 69533696,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 34, 34, 976127)}
2022-05-10 23:34:35 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:35:18 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:35:18 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:35:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:35:18 [scrapy.extensions.telnet] INFO: Telnet Password: 092b0918ef317e58
2022-05-10 23:35:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:35:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:35:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:35:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:35:18 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:35:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:35:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:35:18 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:35:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 886,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 26256,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.119458,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 35, 18, 808974),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 139596,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69468160,
 'memusage/startup': 69468160,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 35, 18, 689516)}
2022-05-10 23:35:18 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:51:15 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:51:15 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:51:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:51:15 [scrapy.extensions.telnet] INFO: Telnet Password: 14f4e1d402814378
2022-05-10 23:51:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:51:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:51:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:51:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:51:15 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:51:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:51:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    print(response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="tit"]').extract)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="tit"]
2022-05-10 23:51:15 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:51:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.734851,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 51, 15, 983820),
 'httpcache/firsthand': 2,
 'httpcache/miss': 2,
 'httpcache/store': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 68927488,
 'memusage/startup': 68927488,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 51, 15, 248969)}
2022-05-10 23:51:15 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:51:53 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:51:53 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:51:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:51:53 [scrapy.extensions.telnet] INFO: Telnet Password: e575d952d05409b2
2022-05-10 23:51:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:51:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:51:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:51:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:51:53 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:51:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:51:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:51:54 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:51:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.140452,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 51, 54, 74242),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69451776,
 'memusage/startup': 69451776,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 51, 53, 933790)}
2022-05-10 23:51:54 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:52:49 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:52:49 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:52:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:52:49 [scrapy.extensions.telnet] INFO: Telnet Password: 8973b0db50cdef8d
2022-05-10 23:52:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:52:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:52:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:52:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:52:49 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:52:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:52:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:52:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    print(response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="tit"]/text()'.format(i).data).extract)
AttributeError: 'str' object has no attribute 'data'
2022-05-10 23:52:49 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:52:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.227533,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 52, 49, 494969),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 68993024,
 'memusage/startup': 68993024,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 52, 49, 267436)}
2022-05-10 23:52:49 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:53:00 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:53:00 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:53:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:53:00 [scrapy.extensions.telnet] INFO: Telnet Password: 4029dee51b6bb37f
2022-05-10 23:53:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:53:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:53:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:53:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:53:00 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:53:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:53:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:53:00 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:53:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.129225,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 53, 0, 442585),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 68878336,
 'memusage/startup': 68878336,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 53, 0, 313360)}
2022-05-10 23:53:00 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:53:21 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:53:21 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:53:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:53:21 [scrapy.extensions.telnet] INFO: Telnet Password: ba34d248b2c373b3
2022-05-10 23:53:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:53:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:53:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:53:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:53:21 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:53:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:53:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:53:21 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:53:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.13747,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 53, 21, 634215),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69566464,
 'memusage/startup': 69566464,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 53, 21, 496745)}
2022-05-10 23:53:21 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:56:51 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:56:51 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:56:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:56:51 [scrapy.extensions.telnet] INFO: Telnet Password: 3b9fbf7287ec8eb7
2022-05-10 23:56:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:56:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:56:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:56:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:56:51 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:56:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:56:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:56:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-10 23:56:51 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:56:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.231205,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 56, 51, 752002),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 68976640,
 'memusage/startup': 68976640,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 56, 51, 520797)}
2022-05-10 23:56:51 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:58:16 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:58:16 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:58:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:58:16 [scrapy.extensions.telnet] INFO: Telnet Password: 6f26abb54af5e0d4
2022-05-10 23:58:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:58:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:58:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:58:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:58:16 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:58:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:58:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:58:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
AttributeError: 'SelectorList' object has no attribute 'format'
2022-05-10 23:58:16 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:58:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.232369,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 58, 16, 469839),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69189632,
 'memusage/startup': 69189632,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 58, 16, 237470)}
2022-05-10 23:58:16 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:58:28 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:58:28 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:58:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:58:28 [scrapy.extensions.telnet] INFO: Telnet Password: 62d615497a1a0094
2022-05-10 23:58:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:58:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:58:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:58:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:58:28 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:58:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:58:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:58:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
AttributeError: 'SelectorList' object has no attribute 'format'
2022-05-10 23:58:28 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:58:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.229262,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 58, 28, 945789),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69894144,
 'memusage/startup': 69894144,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 58, 28, 716527)}
2022-05-10 23:58:28 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-10 23:58:50 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-10 23:58:50 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-10 23:58:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-10 23:58:50 [scrapy.extensions.telnet] INFO: Telnet Password: 5b26a4c148db2d43
2022-05-10 23:58:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-10 23:58:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-10 23:58:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-10 23:58:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-10 23:58:50 [scrapy.core.engine] INFO: Spider opened
2022-05-10 23:58:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-10 23:58:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-10 23:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract()
AttributeError: 'SelectorList' object has no attribute 'format'
2022-05-10 23:58:51 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-10 23:58:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.22824,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 14, 58, 51, 114373),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69353472,
 'memusage/startup': 69353472,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 14, 58, 50, 886133)}
2022-05-10 23:58:51 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:00:47 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:00:47 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:00:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:00:47 [scrapy.extensions.telnet] INFO: Telnet Password: 857ad52b68214ca5
2022-05-11 00:00:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:00:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:00:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:00:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:00:47 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:00:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:00:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:00:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:00:47 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:00:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.225245,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 0, 47, 857301),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69468160,
 'memusage/startup': 69468160,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 0, 47, 632056)}
2022-05-11 00:00:47 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:00:55 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:00:55 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:00:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:00:55 [scrapy.extensions.telnet] INFO: Telnet Password: e31562745a27c1ce
2022-05-11 00:00:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:00:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:00:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:00:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:00:55 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:00:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:00:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:00:55 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:00:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.130076,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 0, 55, 502115),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69222400,
 'memusage/startup': 69222400,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 0, 55, 372039)}
2022-05-11 00:00:55 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:01:57 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:01:57 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:01:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:01:57 [scrapy.extensions.telnet] INFO: Telnet Password: 8d9c9f67e76eec97
2022-05-11 00:01:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:01:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:01:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:01:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:01:57 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:01:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:01:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:01:58 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:01:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.122076,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 1, 58, 134280),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69746688,
 'memusage/startup': 69746688,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 1, 58, 12204)}
2022-05-11 00:01:58 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:02:06 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:02:06 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:02:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:02:06 [scrapy.extensions.telnet] INFO: Telnet Password: aeaef60ddab283ad
2022-05-11 00:02:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:02:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:02:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:02:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:02:06 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:02:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:02:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:02:07 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:02:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.130027,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 2, 7, 132329),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69500928,
 'memusage/startup': 69500928,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 2, 7, 2302)}
2022-05-11 00:02:07 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:02:15 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:02:15 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:02:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:02:15 [scrapy.extensions.telnet] INFO: Telnet Password: cd87154fe9d38762
2022-05-11 00:02:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:02:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:02:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:02:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:02:15 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:02:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:02:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:02:15 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:02:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.128194,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 2, 15, 577322),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69419008,
 'memusage/startup': 69419008,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 2, 15, 449128)}
2022-05-11 00:02:15 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:02:19 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:02:19 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:02:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:02:19 [scrapy.extensions.telnet] INFO: Telnet Password: ebd9866ea7e34e55
2022-05-11 00:02:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:02:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:02:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:02:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:02:19 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:02:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:02:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:02:19 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:02:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.219106,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 2, 19, 728245),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69763072,
 'memusage/startup': 69763072,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 2, 19, 509139)}
2022-05-11 00:02:19 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:02:31 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:02:31 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:02:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:02:31 [scrapy.extensions.telnet] INFO: Telnet Password: 600a9b35c95a558b
2022-05-11 00:02:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:02:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:02:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:02:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:02:31 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:02:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:02:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:02:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:02:31 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:02:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.216455,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 2, 31, 818559),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69173248,
 'memusage/startup': 69173248,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 2, 31, 602104)}
2022-05-11 00:02:31 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:03:12 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:03:12 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:03:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:03:12 [scrapy.extensions.telnet] INFO: Telnet Password: a32d734af9f75021
2022-05-11 00:03:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:03:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:03:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:03:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:03:12 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:03:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:03:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:03:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 25, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:03:12 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:03:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.21346,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 3, 12, 697488),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69713920,
 'memusage/startup': 69713920,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 3, 12, 484028)}
2022-05-11 00:03:12 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:05:27 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:05:27 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:05:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:05:27 [scrapy.extensions.telnet] INFO: Telnet Password: 1d4621cd351754f1
2022-05-11 00:05:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:05:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:05:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:05:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:05:27 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:05:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:05:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:05:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 27, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:05:27 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:05:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.220408,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 5, 27, 777845),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69402624,
 'memusage/startup': 69402624,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 5, 27, 557437)}
2022-05-11 00:05:27 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:05:45 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:05:45 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:05:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:05:45 [scrapy.extensions.telnet] INFO: Telnet Password: 5c10830fc264df22
2022-05-11 00:05:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:05:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:05:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:05:45 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:05:45 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:05:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:05:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:05:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 26, in parse
    print(response.xpath('//*[@id="content"]/div[{}]/div[2]/a/span[3]/text()'.format()).extract_first())
IndexError: Replacement index 0 out of range for positional args tuple
2022-05-11 00:05:45 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:05:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.215152,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 5, 45, 357167),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69632000,
 'memusage/startup': 69632000,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 5, 45, 142015)}
2022-05-11 00:05:45 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:05:52 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:05:52 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:05:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:05:52 [scrapy.extensions.telnet] INFO: Telnet Password: aa020e4863fcec0b
2022-05-11 00:05:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:05:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:05:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:05:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:05:52 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:05:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:05:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:05:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 27, in parse
    date = response.xpath('//*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()').format(i).extract_first()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/http/response/text.py", line 128, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 260, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/opt/homebrew/lib/python3.9/site-packages/six.py", line 718, in reraise
    raise value.with_traceback(tb)
  File "/opt/homebrew/lib/python3.9/site-packages/parsel/selector.py", line 254, in xpath
    result = xpathev(query, namespaces=nsp,
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //*[@id="content"]/div[{}]/div[@class="rightList"]/a/span[@class="date"]/text()
2022-05-11 00:05:52 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:05:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.218671,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 5, 52, 388805),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69206016,
 'memusage/startup': 69206016,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 5, 52, 170134)}
2022-05-11 00:05:52 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:06:14 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:06:14 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:06:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:06:14 [scrapy.extensions.telnet] INFO: Telnet Password: cfcfba2a2e9a63a2
2022-05-11 00:06:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:06:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:06:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:06:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:06:14 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:06:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:06:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:06:14 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:06:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.125104,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 6, 14, 285093),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69730304,
 'memusage/startup': 69730304,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 6, 14, 159989)}
2022-05-11 00:06:14 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:06:33 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:06:33 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:06:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:06:33 [scrapy.extensions.telnet] INFO: Telnet Password: add1fcaf7a142463
2022-05-11 00:06:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:06:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:06:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:06:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:06:34 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:06:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:06:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:06:34 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:06:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.122227,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 6, 34, 191402),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69124096,
 'memusage/startup': 69124096,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 6, 34, 69175)}
2022-05-11 00:06:34 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:06:41 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:06:41 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:06:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:06:41 [scrapy.extensions.telnet] INFO: Telnet Password: e5f93b27ac28d15a
2022-05-11 00:06:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:06:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:06:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:06:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:06:41 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:06:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:06:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:06:41 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:06:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.125359,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 6, 41, 342098),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69632000,
 'memusage/startup': 69632000,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 6, 41, 216739)}
2022-05-11 00:06:41 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:06:59 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:06:59 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:06:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:06:59 [scrapy.extensions.telnet] INFO: Telnet Password: a0d00f2fadc3c348
2022-05-11 00:06:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:06:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:06:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:06:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:06:59 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:06:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:06:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:06:59 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:06:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.124621,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 6, 59, 518915),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69500928,
 'memusage/startup': 69500928,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 6, 59, 394294)}
2022-05-11 00:06:59 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:08:58 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:08:58 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:08:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:08:58 [scrapy.extensions.telnet] INFO: Telnet Password: 324b533bc7340bd3
2022-05-11 00:08:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:08:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:08:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:08:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:08:58 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:08:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:08:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:08:59 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:08:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.125613,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 8, 59, 93122),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 69386240,
 'memusage/startup': 69386240,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 8, 58, 967509)}
2022-05-11 00:08:59 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:09:52 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:09:52 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:09:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:09:52 [scrapy.extensions.telnet] INFO: Telnet Password: f4c219da2e60faa8
2022-05-11 00:09:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:09:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:09:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:09:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:09:52 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:09:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:09:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:09:53 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:09:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 501,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 14095,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 0.140242,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 9, 53, 133039),
 'httpcache/hit': 2,
 'httpcompression/response_bytes': 60972,
 'httpcompression/response_count': 2,
 'log_count/INFO': 10,
 'memusage/max': 68943872,
 'memusage/startup': 68943872,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 9, 52, 992797)}
2022-05-11 00:09:53 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:16:22 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:16:22 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:16:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:16:22 [scrapy.extensions.telnet] INFO: Telnet Password: 81949f3952ba4c2d
2022-05-11 00:16:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:16:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:16:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:16:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:16:22 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:16:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:16:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:16:23 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:16:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 779,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27473,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.437196,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 16, 23, 335034),
 'httpcache/firsthand': 1,
 'httpcache/hit': 2,
 'httpcache/miss': 1,
 'httpcache/store': 1,
 'httpcompression/response_bytes': 120814,
 'httpcompression/response_count': 3,
 'log_count/INFO': 10,
 'memusage/max': 68911104,
 'memusage/startup': 68911104,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 5, 10, 15, 16, 22, 897838)}
2022-05-11 00:16:23 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:17:13 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:17:13 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:17:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:17:13 [scrapy.extensions.telnet] INFO: Telnet Password: 61e8e498cbfdb7f5
2022-05-11 00:17:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:17:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:17:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:17:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:17:13 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:17:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:17:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:17:14 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:17:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 779,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27473,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.16704,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 17, 14, 9858),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 120814,
 'httpcompression/response_count': 3,
 'log_count/INFO': 10,
 'memusage/max': 69746688,
 'memusage/startup': 69746688,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 5, 10, 15, 17, 13, 842818)}
2022-05-11 00:17:14 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:23:14 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:23:14 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:23:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:23:14 [scrapy.extensions.telnet] INFO: Telnet Password: 5e5bab90467d088d
2022-05-11 00:23:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:23:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:23:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:23:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:23:14 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:23:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:23:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:23:14 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:23:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27646,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.472499,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 23, 14, 612626),
 'httpcache/firsthand': 1,
 'httpcache/hit': 2,
 'httpcache/miss': 1,
 'httpcache/store': 1,
 'httpcompression/response_bytes': 118025,
 'httpcompression/response_count': 3,
 'log_count/INFO': 10,
 'memusage/max': 69173248,
 'memusage/startup': 69173248,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 5, 10, 15, 23, 14, 140127)}
2022-05-11 00:23:14 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:23:39 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:23:40 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:23:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:23:40 [scrapy.extensions.telnet] INFO: Telnet Password: d400cc559806998e
2022-05-11 00:23:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:23:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:23:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:23:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:23:40 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:23:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:23:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:23:40 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:23:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27404,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.843443,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 23, 40, 932500),
 'httpcache/firsthand': 2,
 'httpcache/hit': 1,
 'httpcache/miss': 2,
 'httpcache/store': 2,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'log_count/INFO': 10,
 'memusage/max': 69287936,
 'memusage/startup': 69287936,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 5, 10, 15, 23, 40, 89057)}
2022-05-11 00:23:40 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:23:46 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:23:46 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:23:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:23:46 [scrapy.extensions.telnet] INFO: Telnet Password: 0ed270baf6d88aae
2022-05-11 00:23:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:23:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:23:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:23:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:23:46 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:23:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:23:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:23:46 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:23:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27404,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.156046,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 23, 46, 331372),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'log_count/INFO': 10,
 'memusage/max': 69255168,
 'memusage/startup': 69255168,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2022, 5, 10, 15, 23, 46, 175326)}
2022-05-11 00:23:46 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:29:42 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:29:42 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:29:51 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:29:51 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:29:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:29:51 [scrapy.extensions.telnet] INFO: Telnet Password: 5f8aa5ecf3f7425a
2022-05-11 00:29:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:29:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:29:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:29:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:29:51 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:29:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:29:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:29:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 27, in parse
    print(datetime.fromisoformat(date).strftime("%Y-%m-%d"))
TypeError: fromisoformat: argument must be str
2022-05-11 00:29:51 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:29:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27404,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.252776,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 29, 51, 627252),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 69206016,
 'memusage/startup': 69206016,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 29, 51, 374476)}
2022-05-11 00:29:51 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:34:46 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:34:46 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:34:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 00:34:46 [scrapy.extensions.telnet] INFO: Telnet Password: 75f672b9769b6bcf
2022-05-11 00:34:46 [py.warnings] WARNING: /opt/homebrew/lib/python3.9/site-packages/scrapy/extensions/feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2022-05-11 00:34:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 00:34:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 00:34:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 00:34:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-05-11 00:34:46 [scrapy.core.engine] INFO: Spider opened
2022-05-11 00:34:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 00:34:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 00:34:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 27, in parse
    print(datetime.fromisoformat(date).strftime("%Y-%m-%d"))
TypeError: fromisoformat: argument must be str
2022-05-11 00:34:46 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 00:34:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27404,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 0.238748,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 15, 34, 46, 726363),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 68993024,
 'memusage/startup': 68993024,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 15, 34, 46, 487615)}
2022-05-11 00:34:46 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 00:50:18 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:50:18 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:51:29 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 00:51:29 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 00:55:49 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 00:55:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/middleware.py", line 40, in from_settings
    mwcls = load_object(clspath)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/opt/homebrew/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/pipelines.py", line 18, in <module>
    from scrapy.conf import settings
ModuleNotFoundError: No module named 'scrapy.conf'
2022-05-11 00:56:17 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 00:56:17 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/middleware.py", line 40, in from_settings
    mwcls = load_object(clspath)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/opt/homebrew/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/pipelines.py", line 20, in <module>
    from scrapy import log
ImportError: cannot import name 'log' from 'scrapy' (/opt/homebrew/lib/python3.9/site-packages/scrapy/__init__.py)
2022-05-11 00:56:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 28, in parse
    item['date'] = datetime.fromisoformat(date).strftime("%Y-%m-%d")
TypeError: fromisoformat: argument must be str
2022-05-11 00:59:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 28, in parse
    item['date'] = datetime.fromisoformat(date).strftime("%Y-%m-%d")
TypeError: fromisoformat: argument must be str
2022-05-11 01:00:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 37, in parse
    item['date'] = datetime.fromisoformat(date).strftime("%Y-%m-%d")
TypeError: fromisoformat: argument must be str
2022-05-11 01:10:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 36, in parse
    item['date'] = datetime.fromisoformat(date).strftime("%Y-%m-%d")
TypeError: fromisoformat: argument must be str
2022-05-11 01:23:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/ScrapyNews/ScrapyNews/spiders/news.py", line 37, in parse
    item['date'] = datetime.fromisoformat(date).strftime("%Y-%m-%d")
TypeError: fromisoformat: argument must be str
2022-05-11 01:23:28 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:23:28 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:23:46 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:23:46 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:24:05 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:24:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:34:48 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:34:48 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:35:28 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:35:28 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:36:31 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-11 01:36:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/crawler.py", line 103, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2022-05-11 01:41:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 28, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 01:51:57 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 16, in start_requests
    yield scrapy.Reqest(url=url, callback=self.parse)
AttributeError: module 'scrapy' has no attribute 'Reqest'
2022-05-11 01:52:13 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 17, in start_requests
    yield scrapy.Reqest(url=url, callback=self.parse)
AttributeError: module 'scrapy' has no attribute 'Reqest'
2022-05-11 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 22, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 02:30:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 22, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 02:30:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 22, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:03:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:04:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:06:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:07:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:07:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:09:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:11:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:13:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:14:50 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 03:14:50 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 03:14:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 03:14:50 [scrapy.extensions.telnet] INFO: Telnet Password: 45bb83622b5b2969
2022-05-11 03:14:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 03:14:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 03:14:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 03:14:50 [scrapy.middleware] INFO: Enabled item pipelines:
['ScrapyNews.pipelines.CsvPipeline']
2022-05-11 03:14:50 [scrapy.core.engine] INFO: Spider opened
2022-05-11 03:14:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 03:14:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 03:14:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:14:57 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 03:14:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27298,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 6.855771,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 18, 14, 57, 621308),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'item_scraped_count': 39,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 74072064,
 'memusage/startup': 74072064,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 18, 14, 50, 765537)}
2022-05-11 03:14:57 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-11 03:22:56 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-11 03:22:56 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-11 03:22:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-11 03:22:56 [scrapy.extensions.telnet] INFO: Telnet Password: 1ac3c2a40e90fa97
2022-05-11 03:22:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2022-05-11 03:22:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-11 03:22:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-11 03:22:56 [scrapy.middleware] INFO: Enabled item pipelines:
['ScrapyNews.pipelines.CsvPipeline']
2022-05-11 03:22:56 [scrapy.core.engine] INFO: Spider opened
2022-05-11 03:22:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-11 03:22:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-11 03:23:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=0&prod=news&ymd=&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 21, in parse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-11 03:23:04 [scrapy.core.engine] INFO: Closing spider (finished)
2022-05-11 03:23:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 780,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 27298,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 7.19173,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 5, 10, 18, 23, 4, 67801),
 'httpcache/hit': 3,
 'httpcompression/response_bytes': 116733,
 'httpcompression/response_count': 3,
 'item_scraped_count': 39,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 74039296,
 'memusage/startup': 74039296,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2022, 5, 10, 18, 22, 56, 876071)}
2022-05-11 03:23:04 [scrapy.core.engine] INFO: Spider closed (finished)
2022-05-12 16:18:11 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: ScrapyNews)
2022-05-12 16:18:11 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.4.0, Python 3.9.12 (main, Mar 26 2022, 15:44:31) - [Clang 13.1.6 (clang-1316.0.21.2)], pyOpenSSL 22.0.0 (OpenSSL 3.0.3 3 May 2022), cryptography 37.0.2, Platform macOS-12.3.1-arm64-arm-64bit
2022-05-12 16:18:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ScrapyNews',
 'CONCURRENT_REQUESTS': 1,
 'DOWNLOAD_DELAY': 0.25,
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'spider.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'ScrapyNews.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ScrapyNews.spiders']}
2022-05-12 16:18:11 [scrapy.extensions.telnet] INFO: Telnet Password: dd79c1fbc2569468
2022-05-12 16:18:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2022-05-12 16:18:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2022-05-12 16:18:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-12 16:18:11 [scrapy.middleware] INFO: Enabled item pipelines:
['ScrapyNews.pipelines.CsvPipeline']
2022-05-12 16:18:11 [scrapy.core.engine] INFO: Spider opened
2022-05-12 16:18:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-12 16:18:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=1&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=21&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=41&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=61&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=81&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=101&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=121&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=141&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=161&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=181&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=201&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=221&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=241&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=261&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.donga.com/news/List?p=281&prod=news&ymd=20220511&m=NP> (referer: None)
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/defer.py", line 132, in iter_errback
    yield next(it)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/utils/python.py", line 354, in __next__
    return next(self.data)
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "/Users/choihyewon/VScode/capstone-2022-29/DM/Crawling/ScrapyNews/ScrapyNews/spiders/news.py", line 32, in dongaParse
    article = Article(url)
  File "/opt/homebrew/lib/python3.9/site-packages/newspaper/article.py", line 63, in __init__
    source_url = scheme + '://' + urls.get_domain(url)
TypeError: can only concatenate str (not "NoneType") to str
2022-05-12 16:18:16 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2022-05-12 16:18:16 [scrapy.core.engine] INFO: Closing spider (shutdown)
2022-05-12 16:19:18 [scrapy.extensions.logstats] INFO: Crawled 37 pages (at 37 pages/min), scraped 195 items (at 195 items/min)
2022-05-12 16:19:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 9351,
 'downloader/request_count': 37,
 'downloader/request_method_count/GET': 37,
 'downloader/response_bytes': 522261,
 'downloader/response_count': 37,
 'downloader/response_status_count/200': 37,
 'elapsed_time_seconds': 99.52253,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 5, 12, 7, 19, 51, 296619),
 'httpcache/firsthand': 5,
 'httpcache/hit': 32,
 'httpcache/miss': 5,
 'httpcache/store': 5,
 'httpcompression/response_bytes': 2542021,
 'httpcompression/response_count': 37,
 'item_scraped_count': 300,
 'log_count/ERROR': 15,
 'log_count/INFO': 12,
 'memusage/max': 198000640,
 'memusage/startup': 73760768,
 'response_received_count': 37,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 2,
 'scheduler/dequeued': 35,
 'scheduler/dequeued/memory': 35,
 'scheduler/enqueued': 35,
 'scheduler/enqueued/memory': 35,
 'spider_exceptions/TypeError': 15,
 'start_time': datetime.datetime(2022, 5, 12, 7, 18, 11, 774089)}
2022-05-12 16:19:51 [scrapy.core.engine] INFO: Spider closed (shutdown)
2022-05-12 16:19:51 [scrapy.core.engine] INFO: Error while scheduling new request
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/task.py", line 526, in _oneWorkUnit
    result = next(self._iterator)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.9/site-packages/twisted/internet/defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/homebrew/lib/python3.9/site-packages/scrapy/core/engine.py", line 187, in <lambda>
    d.addBoth(lambda _: self.slot.nextcall.schedule())
AttributeError: 'NoneType' object has no attribute 'nextcall'
